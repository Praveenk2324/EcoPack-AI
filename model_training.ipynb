{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Training\n",
                "\n",
                "This notebook performs:\n",
                "1. Load Processed Data (`cleaned_data.csv`)\n",
                "2. Train Sustainability Predictor (XGBoost)\n",
                "3. Train Cost Predictor (Random Forest)\n",
                "4. Save Models for Deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "import xgboost as xgb\n",
                "import joblib\n",
                "import os\n",
                "from datetime import datetime\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load cleaned data\n",
                "try:\n",
                "    history_df = pd.read_csv('cleaned_data.csv')\n",
                "    materials_df = pd.read_csv('materials_database_600 (1).csv')\n",
                "    print(\"‚úÖ Data loaded successfully!\")\n",
                "    print(f\"History Data Shape: {history_df.shape}\")\n",
                "    print(f\"Materials Database Shape: {materials_df.shape}\")\n",
                "except FileNotFoundError:\n",
                "    print(\"‚ùå cleaned_data.csv not found! Please run data_cleaning.ipynb first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Training (Sustainability Predictor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features and target\n",
                "# Features: Weight_kg, Distance_km, Shipping_Mode (One-Hot Encoded), \n",
                "#           Material_CO2_Factor, Material_Density\n",
                "# Target: CO2_Emission_kg\n",
                "\n",
                "# Select features\n",
                "feature_cols = ['Weight_kg', 'Distance_km', 'Shipping_Mode', \n",
                "                'Material_CO2_Factor', 'Material_Density']\n",
                "\n",
                "# Create feature dataframe\n",
                "X = history_df[feature_cols].copy()\n",
                "y = history_df['CO2_Emission_kg'].copy()\n",
                "\n",
                "print(f\"Feature shape: {X.shape}\")\n",
                "print(f\"Target shape: {y.shape}\")\n",
                "print(f\"\\nMissing values in features:\")\n",
                "print(X.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# One-Hot Encode Shipping_Mode\n",
                "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
                "shipping_encoded = encoder.fit_transform(X[['Shipping_Mode']])\n",
                "shipping_feature_names = encoder.get_feature_names_out(['Shipping_Mode'])\n",
                "\n",
                "# Create encoded dataframe\n",
                "X_encoded = pd.DataFrame(\n",
                "    shipping_encoded,\n",
                "    columns=shipping_feature_names,\n",
                "    index=X.index\n",
                ")\n",
                "\n",
                "# Add other numerical features\n",
                "X_encoded['Weight_kg'] = X['Weight_kg']\n",
                "X_encoded['Distance_km'] = X['Distance_km']\n",
                "X_encoded['Material_CO2_Factor'] = X['Material_CO2_Factor']\n",
                "X_encoded['Material_Density'] = X['Material_Density']\n",
                "\n",
                "print(\"Features after encoding:\")\n",
                "print(X_encoded.columns.tolist())\n",
                "print(f\"\\nFeature shape: {X_encoded.shape}\")\n",
                "X_encoded.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data into train (80%) and test (20%)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X_encoded, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Training set: {X_train.shape[0]} samples\")\n",
                "print(f\"Test set: {X_test.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train XGBoost for CO2 prediction\n",
                "xgb_co2_model = xgb.XGBRegressor(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    learning_rate=0.1,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "print(\"Training XGBoost for CO2 Prediction...\")\n",
                "xgb_co2_model.fit(X_train, y_train)\n",
                "print(\"XGBoost CO2 Prediction Training completed!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on test set and evaluate XGBoost CO2 model\n",
                "y_pred_xgb = xgb_co2_model.predict(X_test)\n",
                "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
                "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
                "\n",
                "print(f\"XGBoost CO2 Prediction RMSE on Test Set: {rmse_xgb:.4f}\")\n",
                "print(f\"XGBoost CO2 Prediction MAE on Test Set: {mae_xgb:.4f}\")\n",
                "print(f\"Mean CO2 Emission: {y_test.mean():.4f}\")\n",
                "print(f\"RMSE as % of mean: {(rmse_xgb/y_test.mean())*100:.2f}%\")\n",
                "print(f\"MAE as % of mean: {(mae_xgb/y_test.mean())*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Cost Predictor Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features and target for cost prediction\n",
                "# Features: Weight_kg, Distance_km, Shipping_Mode (One-Hot Encoded), \n",
                "#           Material_Density, Cost_per_kg, Product_Volume_m3\n",
                "# Target: Cost_USD\n",
                "\n",
                "# Select features for cost prediction\n",
                "cost_feature_cols = ['Weight_kg', 'Distance_km', 'Shipping_Mode', \n",
                "                     'Material_Density', 'Cost_per_kg', 'Product_Volume_m3']\n",
                "\n",
                "# Create feature dataframe for cost prediction\n",
                "X_cost = history_df[cost_feature_cols].copy()\n",
                "y_cost = history_df['Cost_USD'].copy()\n",
                "\n",
                "print(f\"Cost Prediction Feature shape: {X_cost.shape}\")\n",
                "print(f\"Cost Prediction Target shape: {y_cost.shape}\")\n",
                "print(f\"\\nMissing values in cost features:\")\n",
                "print(X_cost.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# One-Hot Encode Shipping_Mode for cost prediction\n",
                "encoder_cost = OneHotEncoder(sparse_output=False, drop='first')\n",
                "shipping_encoded_cost = encoder_cost.fit_transform(X_cost[['Shipping_Mode']])\n",
                "shipping_feature_names_cost = encoder_cost.get_feature_names_out(['Shipping_Mode'])\n",
                "\n",
                "# Create encoded dataframe for cost prediction\n",
                "X_cost_encoded = pd.DataFrame(\n",
                "    shipping_encoded_cost,\n",
                "    columns=shipping_feature_names_cost,\n",
                "    index=X_cost.index\n",
                ")\n",
                "\n",
                "# Add other numerical features\n",
                "X_cost_encoded['Weight_kg'] = X_cost['Weight_kg']\n",
                "X_cost_encoded['Distance_km'] = X_cost['Distance_km']\n",
                "X_cost_encoded['Material_Density'] = X_cost['Material_Density']\n",
                "X_cost_encoded['Cost_per_kg'] = X_cost['Cost_per_kg']\n",
                "X_cost_encoded['Product_Volume_m3'] = X_cost['Product_Volume_m3']\n",
                "\n",
                "print(\"Cost Prediction Features after encoding:\")\n",
                "print(X_cost_encoded.columns.tolist())\n",
                "print(f\"\\nCost Prediction Feature shape: {X_cost_encoded.shape}\")\n",
                "X_cost_encoded.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data into train (80%) and test (20%) for cost prediction\n",
                "X_cost_train, X_cost_test, y_cost_train, y_cost_test = train_test_split(\n",
                "    X_cost_encoded, y_cost, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Cost Prediction Training set: {X_cost_train.shape[0]} samples\")\n",
                "print(f\"Cost Prediction Test set: {X_cost_test.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train RandomForestRegressor for cost prediction\n",
                "rf_cost_model = RandomForestRegressor(\n",
                "    n_estimators=100,\n",
                "    max_depth=20,\n",
                "    min_samples_split=5,\n",
                "    min_samples_leaf=2,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "print(\"Training RandomForestRegressor for Cost Prediction...\")\n",
                "rf_cost_model.fit(X_cost_train, y_cost_train)\n",
                "print(\"Cost Prediction Training completed!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on test set and evaluate cost prediction model\n",
                "y_cost_pred = rf_cost_model.predict(X_cost_test)\n",
                "cost_rmse = np.sqrt(mean_squared_error(y_cost_test, y_cost_pred))\n",
                "cost_mae = mean_absolute_error(y_cost_test, y_cost_pred)\n",
                "\n",
                "print(f\"Cost Prediction RMSE on Test Set: ${cost_rmse:.4f}\")\n",
                "print(f\"Cost Prediction MAE on Test Set: ${cost_mae:.4f}\")\n",
                "print(f\"Mean Cost: ${y_cost_test.mean():.4f}\")\n",
                "print(f\"RMSE as % of mean: {(cost_rmse/y_cost_test.mean())*100:.2f}%\")\n",
                "print(f\"MAE as % of mean: {(cost_mae/y_cost_test.mean())*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Save Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_models_for_deployment():\n",
                "    \"\"\"Save all trained models and required components for web deployment\"\"\"\n",
                "    \n",
                "    print(\"=\" * 80)\n",
                "    print(\"üíæ SAVING MODELS FOR WEB DEPLOYMENT\")\n",
                "    print(\"=\" * 80)\n",
                "    \n",
                "    # Create deployment directory\n",
                "    deployment_dir = \"deployment_models\"\n",
                "    if not os.path.exists(deployment_dir):\n",
                "        os.makedirs(deployment_dir)\n",
                "        print(f\"üìÅ Created directory: {deployment_dir}\")\n",
                "    \n",
                "    # Get feature orders for models\n",
                "    co2_feature_order = X_encoded.columns.tolist()\n",
                "    cost_feature_order = X_cost_encoded.columns.tolist()\n",
                "\n",
                "    # Save CO2 prediction model (XGBoost)\n",
                "    co2_model_path = os.path.join(deployment_dir, \"co2_prediction_model.joblib\")\n",
                "    joblib.dump(xgb_co2_model, co2_model_path)\n",
                "    print(f\"‚úÖ CO2 Prediction Model saved: {co2_model_path}\")\n",
                "    \n",
                "    # Save Cost prediction model (Random Forest)\n",
                "    cost_model_path = os.path.join(deployment_dir, \"cost_prediction_model.joblib\")\n",
                "    joblib.dump(rf_cost_model, cost_model_path)\n",
                "    print(f\"‚úÖ Cost Prediction Model saved: {cost_model_path}\")\n",
                "    \n",
                "    # Save encoders\n",
                "    co2_encoder_path = os.path.join(deployment_dir, \"co2_label_encoder.joblib\")\n",
                "    joblib.dump(encoder, co2_encoder_path)\n",
                "    print(f\"‚úÖ CO2 Label Encoder saved: {co2_encoder_path}\")\n",
                "    \n",
                "    cost_encoder_path = os.path.join(deployment_dir, \"cost_label_encoder.joblib\")\n",
                "    joblib.dump(encoder_cost, cost_encoder_path)\n",
                "    print(f\"‚úÖ Cost Label Encoder saved: {cost_encoder_path}\")\n",
                "    \n",
                "    # Save feature orders\n",
                "    co2_features_path = os.path.join(deployment_dir, \"co2_feature_order.joblib\")\n",
                "    joblib.dump(co2_feature_order, co2_features_path)\n",
                "    print(f\"‚úÖ CO2 Feature Order saved: {co2_features_path}\")\n",
                "    \n",
                "    cost_features_path = os.path.join(deployment_dir, \"cost_feature_order.joblib\")\n",
                "    joblib.dump(cost_feature_order, cost_features_path)\n",
                "    print(f\"‚úÖ Cost Feature Order saved: {cost_features_path}\")\n",
                "    \n",
                "    # Save materials database\n",
                "    materials_path = os.path.join(deployment_dir, \"materials_database.joblib\")\n",
                "    joblib.dump(materials_df, materials_path)\n",
                "    print(f\"‚úÖ Materials Database saved: {materials_path}\")\n",
                "    \n",
                "    # Save model metadata\n",
                "    metadata = {\n",
                "        'model_version': '1.0',\n",
                "        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
                "        'co2_model_type': 'XGBoost Regressor',\n",
                "        'cost_model_type': 'Random Forest Regressor',\n",
                "        'co2_rmse': float(rmse_xgb),\n",
                "        'co2_mae': float(mae_xgb),\n",
                "        'cost_rmse': float(cost_rmse),\n",
                "        'cost_mae': float(cost_mae),\n",
                "        'total_materials': len(materials_df),\n",
                "        'categories': materials_df['Category'].unique().tolist(),\n",
                "        'feature_order_co2': co2_feature_order,\n",
                "        'feature_order_cost': cost_feature_order\n",
                "    }\n",
                "    \n",
                "    metadata_path = os.path.join(deployment_dir, \"model_metadata.joblib\")\n",
                "    joblib.dump(metadata, metadata_path)\n",
                "    print(f\"‚úÖ Model Metadata saved: {metadata_path}\")\n",
                "    \n",
                "    # Create requirements.txt for deployment\n",
                "    requirements = [\n",
                "        \"scikit-learn>=1.0.0\",\n",
                "        \"xgboost>=1.6.0\", \n",
                "        \"pandas>=1.3.0\",\n",
                "        \"numpy>=1.21.0\",\n",
                "        \"joblib>=1.1.0\",\n",
                "        \"flask>=2.0.0\"\n",
                "    ]\n",
                "    \n",
                "    requirements_path = os.path.join(deployment_dir, \"requirements.txt\")\n",
                "    with open(requirements_path, 'w') as f:\n",
                "        f.write('\\n'.join(requirements))\n",
                "    print(f\"‚úÖ Requirements file created: {requirements_path}\")\n",
                "    \n",
                " \n",
                "\n",
                "    readme_path = os.path.join(deployment_dir, \"README.md\")\n",
                "    with open(readme_path, 'w') as f:\n",
                "        f.write(\"Model artifacts for Eco Packaging Recommendation\")\n",
                "    print(f\"‚úÖ README documentation created: {readme_path}\")\n",
                "    \n",
                "    print(f\"\\nüéâ DEPLOYMENT PACKAGE CREATED SUCCESSFULLY!\")\n",
                "    print(f\"üìÅ Location: {deployment_dir}/\")\n",
                "\n",
                "# Save all models and deployment files\n",
                "save_models_for_deployment()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}