{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing\n",
    "\n",
    "This notebook performs:\n",
    "1. Data Loading\n",
    "2. Cleaning (Missing values, Invalid dimensions)\n",
    "3. Feature Engineering (Volume calculation)\n",
    "4. Material Mapping\n",
    "5. Exporting processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Try importing fuzzywuzzy, fallback to thefuzz if needed\n",
    "try:\n",
    "    from fuzzywuzzy import fuzz, process\n",
    "except ImportError:\n",
    "    try:\n",
    "        from thefuzz import fuzz, process\n",
    "    except ImportError:\n",
    "        print(\"Warning: fuzzywuzzy or thefuzz not found. Install with: pip install fuzzywuzzy python-Levenshtein\")\n",
    "        # Fallback: simple substring matching only\n",
    "        def process_extractOne(text, choices, scorer=None):\n",
    "            # Simple fallback - just return first match or None\n",
    "            for choice in choices:\n",
    "                if text.lower() in choice.lower() or choice.lower() in text.lower():\n",
    "                    return (choice, 100)\n",
    "            return None\n",
    "        process = type('obj', (object,), {'extractOne': process_extractOne})\n",
    "        fuzz = type('obj', (object,), {'token_sort_ratio': lambda x, y: 0})\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both CSV files\n",
    "history_df = pd.read_csv('real_packaging_history (1).csv')\n",
    "materials_df = pd.read_csv('materials_database_600 (1).csv')\n",
    "\n",
    "print(\"History Data Shape:\", history_df.shape)\n",
    "print(\"Materials Data Shape:\", materials_df.shape)\n",
    "print(\"\\nHistory Columns:\", history_df.columns.tolist())\n",
    "print(\"\\nMaterials Columns:\", materials_df.columns.tolist())\n",
    "print(\"\\nFirst few rows of history:\")\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in history data:\")\n",
    "print(history_df.isnull().sum())\n",
    "print(\"\\nMissing values in materials data:\")\n",
    "print(materials_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing 'Cost_USD' and 'CO2_Emission_kg' with median of their respective 'Category'\n",
    "for col in ['Cost_USD', 'CO2_Emission_kg']:\n",
    "    if history_df[col].isnull().sum() > 0:\n",
    "        category_medians = history_df.groupby('Category')[col].median()\n",
    "        history_df[col] = history_df.apply(\n",
    "            lambda row: category_medians[row['Category']] if pd.isnull(row[col]) else row[col],\n",
    "            axis=1\n",
    "        )\n",
    "        print(f\"Imputed {history_df[col].isnull().sum()} missing values in {col}\")\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(history_df[['Cost_USD', 'CO2_Emission_kg']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix invalid dimensions: If L_cm, W_cm, or H_cm are 0, replace with average for that Category\n",
    "for dim in ['L_cm', 'W_cm', 'H_cm']:\n",
    "    invalid_mask = (history_df[dim] == 0) | (history_df[dim].isnull())\n",
    "    if invalid_mask.sum() > 0:\n",
    "        category_means = history_df.groupby('Category')[dim].mean()\n",
    "        history_df[dim] = history_df.apply(\n",
    "            lambda row: category_means[row['Category']] if (row[dim] == 0 or pd.isnull(row[dim])) else row[dim],\n",
    "            axis=1\n",
    "        )\n",
    "        print(f\"Fixed {invalid_mask.sum()} invalid values in {dim}\")\n",
    "\n",
    "print(\"\\nInvalid dimensions (zeros) after fixing:\")\n",
    "print((history_df[['L_cm', 'W_cm', 'H_cm']] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Product_Volume_m3 as (L*W*H)/1,000,000\n",
    "history_df['Product_Volume_m3'] = (history_df['L_cm'] * history_df['W_cm'] * history_df['H_cm']) / 1_000_000\n",
    "\n",
    "print(\"Product_Volume_m3 calculated successfully!\")\n",
    "print(f\"Volume statistics:\\n{history_df['Product_Volume_m3'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Material Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique packaging names from history and material names from database\n",
    "packaging_used = history_df['Packaging_Used'].unique()\n",
    "material_names = materials_df['Material_Name'].unique()\n",
    "\n",
    "print(f\"Unique packaging types in history: {len(packaging_used)}\")\n",
    "print(f\"Unique materials in database: {len(material_names)}\")\n",
    "print(\"\\nSample packaging types:\", packaging_used[:10])\n",
    "print(\"\\nSample material names:\", material_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping function using fuzzy matching\n",
    "def map_packaging_to_material(packaging_name, material_list, threshold=60):\n",
    "    \"\"\"\n",
    "    Maps packaging name to material name using fuzzy matching.\n",
    "    Also handles common substring matches.\n",
    "    \"\"\"\n",
    "    # Direct substring matching for common cases\n",
    "    packaging_lower = packaging_name.lower()\n",
    "    \n",
    "    # Common mappings\n",
    "    if 'mushroom' in packaging_lower or 'mycelium' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'mushroom' in m.lower() or 'mycelium' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'wood' in packaging_lower or 'crate' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'plywood' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'kraft' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'kraft' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'pla' in packaging_lower or 'bioplastic' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'pla' in m.lower() or 'bioplastic' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'bubble' in packaging_lower or 'ldpe' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'bubble' in m.lower() or 'ldpe' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'pet' in packaging_lower and 'recycled' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'pet' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'honeycomb' in packaging_lower or 'paper' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'paper' in m.lower() or 'honeycomb' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    # Additional mappings for other packaging types\n",
    "    if 'corrugated' in packaging_lower or 'cardboard' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'cardboard' in m.lower() or 'corrugated' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'styrofoam' in packaging_lower or 'eps' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'foam' in m.lower() and 'polyurethane' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    if 'cornstarch' in packaging_lower:\n",
    "        matches = [m for m in material_list if 'cornstarch' in m.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    \n",
    "    # Fuzzy matching as fallback\n",
    "    try:\n",
    "        best_match = process.extractOne(packaging_name, material_list, scorer=fuzz.token_sort_ratio)\n",
    "        if best_match and best_match[1] >= threshold:\n",
    "            return best_match[0]\n",
    "    except:\n",
    "        # If fuzzy matching fails, try simple substring match\n",
    "        for material in material_list:\n",
    "            if packaging_lower in material.lower() or material.lower() in packaging_lower:\n",
    "                return material\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Create mapping dictionary\n",
    "packaging_to_material = {}\n",
    "for packaging in packaging_used:\n",
    "    mapped = map_packaging_to_material(packaging, material_names)\n",
    "    packaging_to_material[packaging] = mapped\n",
    "    if mapped:\n",
    "        print(f\"'{packaging}' -> '{mapped}'\")\n",
    "    else:\n",
    "        print(f\"'{packaging}' -> NOT FOUND\")\n",
    "\n",
    "print(f\"\\nSuccessfully mapped {sum(1 for v in packaging_to_material.values() if v is not None)}/{len(packaging_to_material)} packaging types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping to history dataframe\n",
    "history_df['Material_Name'] = history_df['Packaging_Used'].map(packaging_to_material)\n",
    "\n",
    "# Check how many were successfully mapped\n",
    "print(f\"Mapped rows: {history_df['Material_Name'].notna().sum()}/{len(history_df)}\")\n",
    "print(f\"Unmapped rows: {history_df['Material_Name'].isna().sum()}\")\n",
    "\n",
    "# Show unmapped packaging types\n",
    "if history_df['Material_Name'].isna().sum() > 0:\n",
    "    unmapped = history_df[history_df['Material_Name'].isna()]['Packaging_Used'].unique()\n",
    "    print(f\"\\nUnmapped packaging types: {unmapped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge material properties from materials database\n",
    "# Rename CO2_Emission_kg to Material_CO2_Factor in materials_df for clarity\n",
    "materials_merge = materials_df[['Material_Name', 'Density_kg_m3', 'Cost_per_kg', 'CO2_Emission_kg']].copy()\n",
    "materials_merge = materials_merge.rename(columns={'CO2_Emission_kg': 'Material_CO2_Factor'})\n",
    "\n",
    "# Merge with history dataframe\n",
    "history_df = history_df.merge(\n",
    "    materials_merge,\n",
    "    on='Material_Name',\n",
    "    how='left',\n",
    "    suffixes=('', '_material')\n",
    ")\n",
    "\n",
    "# Rename Density column for clarity\n",
    "history_df = history_df.rename(columns={'Density_kg_m3': 'Material_Density'})\n",
    "\n",
    "print(\"Merged material properties:\")\n",
    "print(f\"Rows with material properties: {history_df['Material_Density'].notna().sum()}/{len(history_df)}\")\n",
    "print(\"\\nSample merged data:\")\n",
    "history_df[['Packaging_Used', 'Material_Name', 'Material_Density', 'Material_CO2_Factor', 'Cost_per_kg']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where material mapping failed (no material properties)\n",
    "initial_rows = len(history_df)\n",
    "history_df = history_df[history_df['Material_Density'].notna()].copy()\n",
    "removed_rows = initial_rows - len(history_df)\n",
    "\n",
    "print(f\"Removed {removed_rows} rows without material mapping\")\n",
    "print(f\"Final dataset size: {len(history_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned and processed data to CSV\n",
    "output_file = 'cleaned_data.csv'\n",
    "history_df.to_csv(output_file, index=False)\n",
    "print(f\"âœ… Successfully saved cleaned data to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
